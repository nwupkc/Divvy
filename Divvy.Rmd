---
title: "Divvy"
author: "Sungwan Kim"
date: "9/5/2017"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

This is a prediction of bicycle sharing usage in the city of Chicago. I have defined the usage as the number of trips taken per day. I will use historical trips and weather datasets from 2014 to 2016 to predict the usage for the first half of 2017. I have decided to exclude trips data from 2013 as the number of rides during summer months are noticeably low as Divvy just started out its service in the Windy City making the prediction less accurate.


## Load Data

```{r packages, results = 'hide'}
# Load packages
library('tidyverse')
library('lubridate')
library('leaps')
library('tree')
library('randomForest')
library('gbm')
```

To jump right into the Exploratory Data Analysis and Feature Engineering, I have written detailed data preparation at the end.

```{r}
train <- read_csv("train.csv")
test <- read_csv("test.csv")

str(train)
```

## Feature Engineering

Let's shed more light into what is driving the Divvy usage. First, I will define usage to be the number of trips taken per day.

```{r}
ggplot(train, aes(Date, Trips)) + geom_line()
```

The graph shows strong seasonal pattern. I will create a variable called quarter so that our models can capture this pattern when predicting.

```{r}
train$Quarter <- 1
train$Quarter[month(train$Date) %in% 4:6] <- 2
train$Quarter[month(train$Date) %in% 7:9] <- 3
train$Quarter[month(train$Date) %in% 10:12] <- 4
train$Quarter <- as.factor(train$Quarter)
```

I will create day of the week variable to see the shorter usage pattern.

```{r}
train <- train %>% 
  mutate(Wday = wday(Date, label = TRUE))
ggplot(train, aes(Wday, Trips)) + geom_boxplot()
```

It seems like usage during week days are little higher than usage during weekends.

```{r}
# First we'll look at the relationship between quarter & wday
ggplot(train, aes(wday, fill = Trips)) + 
  geom_histogram() + 
  # I include Sex since we know (a priori) it's a significant predictor
  facet_grid(.~quarter) + 
  theme_few()
```

## Prediction

### Linear Regression

I will first use linear regression as a starting point and a benchmark.

```{r}
lm.fit <- lm(Trips ~ Temperature_Avg + Dew_Point_Avg + Humidity_Avg + Sea_Level_Press_Avg + Visibility_Avg + Wind_Avg + Precipitation + Events + Wday + Quarter, train)
summary(lm.fit)
```

The model has found temperature, sea level pressure, wind, precipitation, rain, thunderstorm, and quarter2 to be significant. The model has R-squared of 0.6451 which means 64.51% of the trips are explained by this data. So, how did our model do in terms of prediction? 

```{r}
sqrt(mean((test$Trips - predict(lm.fit, test))^2))
```

The linear model has a root mean squared error(RMSE) of 2583.261. I have used RMSE for a metric to evaluate the prediction accuracy. Now let's plot the predicted value along with the actual value. 

```{r}
test$yhat <- predict(lm.fit, test)
graph <- ggplot(test) + 
  geom_line(aes(Date, Trips)) +
  geom_point(aes(Date, yhat))
graph
```

We might want to have an interaction term between variables wday and quarter as it might be more reasonable to assume that usage differ by weekdays for different quarters and vice versa. 

```{r}
lm.fit2 <- lm(Trips ~ Temperature_Avg + Dew_Point_Avg + Humidity_Avg + Sea_Level_Press_Avg + Visibility_Avg + Wind_Avg + Precipitation + Events + Wday * Quarter, train)
summary(lm.fit2)
```

Calculating the RMSE of the second model.

```{r}
sqrt(mean((test$Trips - predict(lm.fit2, test))^2))
```

We did a little better in terms of the prediction. Now, let's see if using all the features is the right way to run the regression. There might be issue of multicollinearity between weather variables as they are likely to be highly correlated.

```{r}
regfit.full <- regsubsets(Trips ~ Temperature_Avg + Dew_Point_Avg + Humidity_Avg + Sea_Level_Press_Avg + Visibility_Avg + Wind_Avg + Precipitation + Events + Wday + Quarter, train)
reg.summary <- summary(regfit.full)
reg.summary$rsq
par(mfrow=c(2,2))
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l")
plot(reg.summary$adjr2,xlab="Number of Variables",ylab="Adjusted RSq",type="l")
which.max(reg.summary$adjr2)
plot(reg.summary$cp,xlab="Number of Variables",ylab="Cp",type="l")
which.min(reg.summary$cp)
plot(reg.summary$bic,xlab="Number of Variables",ylab="BIC",type="l")
which.min(reg.summary$bic)
```

It seems like using all 8 regressors is the right way to go.

### Decision Tree

Next, we will use decision tree to predict the usage.

```{r}
set.seed(11)
tree.divvy <- tree(Trips ~ Temperature_Avg + Dew_Point_Avg + Humidity_Avg + Sea_Level_Press_Avg + Visibility_Avg + Wind_Avg + Precipitation + Events + Wday + Quarter, train)
summary(tree.divvy)
par(mfrow=c(1, 1))
plot(tree.divvy)
text(tree.divvy, pretty = 0)
cv.divvy <- cv.tree(tree.divvy)
plot(cv.divvy$size, cv.divvy$dev, type='b')
```

How did we do in terms of prediction?

```{r}
sqrt(mean((predict(tree.divvy, newdata = test) - test$Trips)^2))
```

We actually did worse than linear model. We can reconcile this issue with using ensemble modeling. Before we move on, let's take a look at the predicted value.

```{r}
test$yhat <- predict(tree.divvy, newdata = test)
graph
```

### Bagging and Random Forest

```{r}
combi <- rbind(train, test[,-25])
train <- combi[1:1284,]
test <- combi[1285:1465,]
```

Instead of using decision trees, we can use many trees to predict the usage. Bagging model is a special case of random forest when we use all the features available.

```{r}
set.seed(11)
bag.divvy <- randomForest(Trips ~ Temperature_Avg + Dew_Point_Avg + Humidity_Avg + Sea_Level_Press_Avg + Visibility_Avg + Wind_Avg + Precipitation + Events + Wday + Quarter, train, mtry=9, importance=TRUE)
```

Let's see how we did.

```{r}
sqrt(mean((predict(bag.divvy, newdata = test) - test$Trips)^2))
```

We did a little better than decision tree, but it is still less accurate than linear regression.

```{r}
test$yhat <- predict(bag.divvy, newdata = test)
graph
```

Now we use random forest. The default is using square root of features in this case 3.

```{r}
rf.divvy <- randomForest(Trips ~ Temperature_Avg + Dew_Point_Avg + Humidity_Avg + Sea_Level_Press_Avg + Visibility_Avg + Wind_Avg + Precipitation + Events + Wday + Quarter, train, mtry=3, importance=TRUE)
importance(rf.divvy)
varImpPlot(rf.divvy)
```

Okay, temperature is the most important variable.

```{r}
sqrt(mean((predict(rf.divvy, newdata = test) - test$Trips)^2))
```

We have done a little better.

```{r}
test$yhat <- predict(rf.divvy, newdata = test)
graph
```

### Boosting

Lastly, we use gradient boosting model.

```{r}
set.seed(11)
boost.divvy <- gbm(Trips ~ Temperature_Avg + Dew_Point_Avg + Humidity_Avg + Sea_Level_Press_Avg + Visibility_Avg + Wind_Avg + Precipitation + Events + Wday + Quarter, train, distribution="gaussian", n.trees=5000, interaction.depth=4)
summary(boost.divvy)
```

RMSE

```{r}
sqrt(mean((predict(boost.divvy, newdata = test,n.trees=5000) - test$Trips)^2))
```

graph

```{r}
test$yhat <- predict(boost.divvy, newdata = test, n.trees=5000)
graph
```


## Data Preparation (Optional)

First I will combine all the trips dataset into one data frame and convert start and stop time into date format.

```{r datasets, results = 'hide'}
trips_2014_Q1Q2 <- read_csv("Divvy_Trips_2014_Q1Q2.csv")
trips_2014_Q3_07 <- read_csv("Divvy_Trips_2014-Q3-07.csv")
trips_2014_Q3_0809 <- read_csv("Divvy_Trips_2014-Q3-0809.csv")
trips_2014_Q4 <- read_csv("Divvy_Trips_2014-Q4.csv")
trips_2015_Q1 <- read_csv("Divvy_Trips_2015-Q1.csv")
trips_2015_Q2 <- read_csv("Divvy_Trips_2015-Q2.csv")
trips_2015_Q3_07 <- read_csv("Divvy_Trips_2015_07.csv")
trips_2015_Q3_08 <- read_csv("Divvy_Trips_2015_08.csv")
trips_2015_Q3_09 <- read_csv("Divvy_Trips_2015_09.csv")
trips_2015_Q4 <- read_csv("Divvy_Trips_2015_Q4.csv")
trips_2016_Q1 <- read_csv("Divvy_Trips_2016_Q1.csv")
trips_2016_Q2_04 <- read_csv("Divvy_Trips_2016_04.csv")
trips_2016_Q2_05 <- read_csv("Divvy_Trips_2016_05.csv")
trips_2016_Q2_06 <- read_csv("Divvy_Trips_2016_06.csv")
trips_2016_Q3 <- read_csv("Divvy_Trips_2016_Q3.csv")
trips_2016_Q4 <- read_csv("Divvy_Trips_2016_Q4.csv")
trips_2017_Q1 <- read_csv("Divvy_Trips_2017_Q1.csv")
trips_2017_Q2 <- read_csv("Divvy_Trips_2017_Q2.csv")

trips <- rbind(trips_2014_Q1Q2, trips_2014_Q3_07, trips_2014_Q3_0809, trips_2014_Q4, 
               trips_2015_Q1, trips_2015_Q2, trips_2015_Q3_07, trips_2015_Q3_08,
               trips_2015_Q3_09, trips_2015_Q4, trips_2016_Q1, trips_2016_Q2_04,
               trips_2016_Q2_05, trips_2016_Q2_06)
trips$starttime <- as_date(mdy_hm(trips$starttime))
trips$stoptime <- as_date(mdy_hm(trips$stoptime))
# starttime and stoptime for 2016 Q3 & Q4 are formatted differently
trips_2016_Q3Q4 <- rbind(trips_2016_Q3, trips_2016_Q4)
trips_2016_Q3Q4$starttime <- as_date(mdy_hms(trips_2016_Q3Q4$starttime))
trips_2016_Q3Q4$stoptime <- as_date(mdy_hms(trips_2016_Q3Q4$stoptime))
trips <- rbind(trips, trips_2016_Q3Q4)
```

Now, in order to get the usage value, we have to first group the number of trips taken by date. There are two options available for date to sum over - start and stop time. There are `r trips$starttime != trips$stoptime` instances where start time are different from the stop time. Since this is only samll percentage, we will use start time to sum together trips.

```{r}
names(trips)[names(trips) == "starttime"] <- "Date"
byday <- trips %>%
  group_by(Date) %>% 
  summarise(Trips = n()) %>% 
```

Now, let's take a look at weather data.

```{r}
weather <- read_csv("chicagoweather.csv")
# convert date
weather$Date <- as_date(dmy(weather$Date))

# "T" stands for "trace", used when precipitation has been detected, but it isn't sufficient to measure meaningfully > so replace all "T"s with 0s.
weather$Precipitation[weather$Precipitation == "T"] <- 0
weather$Precipitation <- as.numeric(weather$Precipitation)
# Treating Events variable
weather[which(is.na(weather$Events)),]$Events <- "None"
weather$Events <- as.factor(weather$Events)
levels(weather$Events)
weather$Events <- gsub("Fog|Fog\\r\\t,\\rRain|Rain", "Rain", weather$Events)
weather$Events <- gsub("Fog\\r\\t,\\rRain\\r\\t,\\rSnow|Fog\\r\\t,\\rSnow|Rain\\r\\t,\\rSnow|Snow", "Snow", weather$Events)
weather$Events <- gsub("Fog\\r\\t,\\rRain\\r\\t,\\rThunderstorm|Rain\\r\\t,\\rHail\\r\\t,\\rThunderstorm|Rain\\r\\t,\\rThunderstorm|Thunderstorm", "Thunderstorm", weather$Events)
weather$Events <- as.factor(weather$Events)
levels(weather$Events)
```

Now we are ready to merge and create our training dataset!

```{r}
train <- weather %>% 
  left_join(byday, by = "Date")
```

There are few missing values in our training data set. These are from the days when there were no trips, so we input the adequate values accordingly.

```{r}
train[which(is.na(train$Trips)),]
which(is.na(train$Trips))
train[195, "Wday"] <- "Tues"
train[196, "Wday"] <- "Wed"
train[which(is.na(train$Quarter)),]$Quarter <- 1
train[which(is.na(train$Trips)),]$Trips <- 0
```

## Test

Now we do the same transformation to trips and weather data for 2017 to create our testing set.

```{r}
weather_2017 <- read_csv("chicagoweather2017.csv")
weather_2017$Date <- as_date(dmy(weather_2017$Date))
weather_2017[which(is.na(weather_2017$Precipitation)),]$Precipitation <- 0
weather_2017$Precipitation <- as.numeric(weather_2017$Precipitation)
weather_2017[which(is.na(weather_2017$Events)),]$Events <- "None"
weather_2017$Events <- as.factor(weather_2017$Events)
levels(weather_2017$Events)
weather_2017$Events <- gsub("Fog|Fog , Rain|Rain", "Rain", weather_2017$Events)
weather_2017$Events <- gsub("Fog , Rain , Snow|Fog , Snow|Rain , Snow|Snow", "Snow", weather_2017$Events)
weather_2017$Events <- gsub("Fog , Rain , Thunderstorm|Fog , Snow , Thunderstorm|Rain , Hail , Thunderstorm|Rain , Thunderstorm|Thunderstorm|Snow , Thunderstorm", "Thunderstorm", weather_2017$Events)
weather_2017$Events <- as.factor(weather_2017$Events)
levels(weather_2017$Events)

trips_2017_Q1 <- read_csv("Divvy_Trips_2017_Q1.csv")
trips_2017_Q2 <- read_csv("Divvy_Trips_2017_Q2.csv")
trips_2017 <- rbind(trips_2017_Q1, trips_2017_Q2)

trips_2017$Date <- as_date(mdy_hms(trips_2017$start_time))
byday3 <- trips_2017 %>% 
  group_by(Date) %>% 
  summarise(Trips = n()) %>% 
  mutate(Wday = wday(Date, label = TRUE))

byday3$Quarter <- 1
byday3$Quarter[month(byday3$Date) %in% 4:6] <- 2
byday3$Quarter[month(byday3$Date) %in% 7:9] <- 3
byday3$Quarter[month(byday3$Date) %in% 10:12] <- 4
byday3$Quarter <- as.factor(byday3$Quarter)
levels(byday3$Quarter) <- levels(byday3$Quarter)

test <- weather_2017 %>% 
  left_join(byday3, by = "Date")
```